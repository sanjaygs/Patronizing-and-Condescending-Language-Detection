{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4c34230",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import re\n",
    "\n",
    "def read_dataset(file_path):\n",
    "    file_path = Path(file_path)\n",
    "\n",
    "    raw_text = file_path.read_text().strip()\n",
    "    raw_docs = raw_text.split('\\n')[4:]\n",
    "#     ids_docs = []\n",
    "#     keywords_docs = []\n",
    "#     texts_docs = []\n",
    "#     labels_docs = []\n",
    "    ids = []\n",
    "    keywords = []\n",
    "    texts = []\n",
    "    labels = []\n",
    "    for line in raw_docs:\n",
    "        \n",
    "#         for line in doc.split('\\n'):\n",
    "        id_, keyword, text, label = line.split('\\t')[0],line.split('\\t')[2],line.split('\\t')[4],line.split('\\t')[5]\n",
    "        ids.append(id_)\n",
    "        keywords.append(keyword)\n",
    "        texts.append(text)\n",
    "        if(label=='0' or label=='1'):\n",
    "            labels.append(0)\n",
    "        else:\n",
    "            labels.append(1)\n",
    "#         labels.append(label)\n",
    "#         token_docs.append(tokens)\n",
    "#         tag_docs.append(tags)\n",
    "\n",
    "    return ids, keywords, texts, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0df39f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "IDs,Keywords,Texts,Labels = read_dataset('dontpatronizeme_pcl.tsv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10374fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_texts, val_texts, train_tags, val_tags = train_test_split(Texts, Labels, test_size=.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03482254",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ac19200",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import RobertaTokenizer, RobertaForMaskedLM\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc49ff27",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = RobertaTokenizer.from_pretrained('roberta-base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d96fc311",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_encodings = tokenizer(train_texts, padding=True, truncation=True)\n",
    "val_encodings = tokenizer(val_texts, padding=True, truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ff3e3ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(train_encodings['input_ids'][0])):\n",
    "    print(train_encodings['input_ids'][0][i],\"---\",train_texts[0].split(' ')[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abd5da4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_texts[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83a11bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_encodings['input_ids']),len(train_tags),len(val_encodings['input_ids']),len(val_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e8b976d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier_Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "train_dataset = Classifier_Dataset(train_encodings, train_tags)\n",
    "val_dataset = Classifier_Dataset(val_encodings, val_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30569f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "227ecb52",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb5e6150",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import RobertaForSequenceClassification, Trainer, TrainingArguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "363a81ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RobertaForSequenceClassification.from_pretrained('roberta-base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91caa7e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',          # output directory\n",
    "    num_train_epochs=2,              # total number of training epochs\n",
    "    per_device_train_batch_size=32,  # batch size per device during training\n",
    "    per_device_eval_batch_size=32,   # batch size for evaluation\n",
    "    warmup_steps=500,                # number of warmup steps for learning rate scheduler\n",
    "    weight_decay=0.01,               # strength of weight decay\n",
    "    logging_dir='./logs',            # directory for storing logs\n",
    "    logging_steps=10,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,                         # the instantiated ðŸ¤— Transformers model to be trained\n",
    "    args=training_args,                  # training arguments, defined above\n",
    "    train_dataset=train_dataset,         # training dataset\n",
    "    eval_dataset=val_dataset             # evaluation dataset\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15150537",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81b19c49",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
